{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T22:38:18.308230Z",
     "start_time": "2024-08-14T22:38:18.294855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def load_config(filename: str) -> object:\n",
    "    file = open(filename).read()\n",
    "    return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "experts = load_config('experts.yml')\n",
    "experts"
   ],
   "id": "255aea07e253c63e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experts': [{'model': 'gpt-3.5-turbo'},\n",
       "  {'model': 'anthropic/claude-3-haiku'},\n",
       "  {'model': 'perplexity/llama-3-sonar-small-32k-online'},\n",
       "  {'model': 'google/palm-2-chat-bison-32k'},\n",
       "  {'model': 'google/gemma-2-9b-it'}]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T22:38:18.335656Z",
     "start_time": "2024-08-14T22:38:18.325823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_template(filename: str) -> str:\n",
    "    file = open(filename, 'r').read()\n",
    "    return file\n",
    "\n",
    "\n",
    "template = load_template('prompt_template.txt')\n",
    "template"
   ],
   "id": "35a01221e6c6b6f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you evaluate how well this example conveys its meaning, how well it is organized and structured, whether it fits the theme of the conversation, and whether its responses are accurate?\\nPlease rate text below from 1 (poor) to 5 (excellent), RESPONSE ONLY ONE NUMBER:\\n\\n{{ context }}\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T22:38:18.392774Z",
     "start_time": "2024-08-14T22:38:18.378237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jinja2 import Template\n",
    "from openai import OpenAI\n",
    "from settings import OPENAI_API_KEY, OPENAI_BASE_URL\n",
    "\n",
    "\n",
    "class Expert:\n",
    "    client = None\n",
    "\n",
    "    def __init__(self, model, base_url=None, api_key=None, prompt_template=None):\n",
    "        self.model = model\n",
    "        self.base_url = base_url or OPENAI_BASE_URL\n",
    "        self.api_key = api_key or OPENAI_API_KEY\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "        if self.client is None:\n",
    "            self.init_client()\n",
    "\n",
    "    def init_client(self):\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def rate_element(self, data: str) -> int | None:\n",
    "        prompt = Template(self.prompt_template).render(context=data)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            n=1,\n",
    "            max_tokens=5  # Amount of OUTPUT tokens\n",
    "        )\n",
    "\n",
    "        # Extract the response text and parse it as an integer rating from 1 to 5\n",
    "        response_text = response.choices[0].message.content\n",
    "        try:\n",
    "            rating = int(''.join(filter(str.isdigit, response_text)))\n",
    "        except ValueError:\n",
    "            print(\"Invalid rating value in response: {}\".format(response_text))\n",
    "            return None\n",
    "\n",
    "        # Ensure the rating is within the valid range [1, 5]\n",
    "        if rating < 1 or rating > 5:\n",
    "            print(\"Rating out of range: {}\".format(rating))\n",
    "            return None\n",
    "\n",
    "        return rating"
   ],
   "id": "4ef84fcab26ca504",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T22:38:20.909961Z",
     "start_time": "2024-08-14T22:38:18.408434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import concurrent.futures\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "\n",
    "config = load_config('experts.yml')\n",
    "template = load_template('prompt_template.txt')\n",
    "experts = [Expert(**expert, prompt_template=template) for expert in config['experts']]\n",
    "encoding = tiktoken.get_encoding(\"gpt2\")  # Load the Tiktoken encoding model for counting tokens\n",
    "\n",
    "\n",
    "# Processing function, due to limitation of concurrent requests in python\n",
    "def process_model(expert: Expert, data: str) -> int:\n",
    "    return expert.rate_element(data)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"IlyaGusev/saiga_scored\", split=\"train[:10]\")  # Replace with your desired dataset name\n",
    "\n",
    "# Get the data to rate from the dataset\n",
    "data_to_rate = [json.dumps(sample[\"messages\"], ensure_ascii=False) for sample in dataset]"
   ],
   "id": "9420ea9de5dd79c9",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T22:39:55.925623Z",
     "start_time": "2024-08-14T22:38:20.915003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ratings_by_experts = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    # Fill object with default structure\n",
    "    ratings_by_expert = {expert: [] for expert in experts}\n",
    "    for i, data in enumerate(data_to_rate):\n",
    "\n",
    "        # Count the number of tokens in the sample using Tiktoken\n",
    "        num_tokens = len(encoding.encode(data))\n",
    "        # Skip processing for large samples with more than 3000 tokens\n",
    "        if num_tokens > 3000:\n",
    "            print(\"Skipping sample {}: Size exceeds limit ({} tokens)\".format(i + 1, num_tokens))\n",
    "            ratings_by_experts.append(None)\n",
    "            continue\n",
    "\n",
    "        print(\"Processing sample {}: {}\".format(i + 1, data))\n",
    "        ratings = list(executor.map(process_model, experts, [data] * len(experts)))\n",
    "        ratings_by_expert = {expert.model: ratings[idx] for idx, expert in enumerate(experts)}\n",
    "        print(\"Ratings:\", ratings)\n",
    "\n",
    "        # Save results\n",
    "        ratings_by_experts.append(ratings_by_expert)"
   ],
   "id": "733eb4a40b245364",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 1: [{\"content\": \"Ideas generales de la Seguridad Social (qué es, para qué sirve, qué has oído\\ndecir de ella...)\", \"role\": \"user\"}, {\"content\": \"La Seguridad Social es un sistema integral diseñado para proteger a los ciudadanos frente a diversas situaciones de vulnerabilidad o necesidad, tales como la vejez, el desempleo, la enfermedad, la discapacidad, la muerte (protección a los dependientes del fallecido) y la maternidad. Este sistema se basa en principios de solidaridad y redistribución de recursos, donde los trabajadores, empleadores y, en algunos casos, el Estado, contribuyen financieramente para sostenerlo.\\n\\nLa Seguridad Social tiene varios propósitos fundamentales:\\n\\n1. **Protección contra la pérdida de ingresos**: Asegura un ingreso básico a las personas que no pueden trabajar debido a vejez, enfermedad, discapacidad, maternidad o desempleo.\\n\\n2. **Acceso a servicios de salud**: Ofrece cobertura de salud para el tratamiento de enfermedades y condiciones médicas, así como para la prevención de estas.\\n\\n3. **Apoyo a familias y dependientes**: Proporciona beneficios a las familias con hijos y en algunos casos, apoyo financiero en caso de muerte de un miembro de la familia que contribuía económicamente.\\n\\n4. **Promoción de la equidad social**: A través de la redistribución de recursos, busca reducir las desigualdades económicas y promover la inclusión social.\\n\\n5. **Estabilidad económica**: Contribuye a la estabilidad económica general al asegurar un nivel mínimo de ingresos para todos, lo que a su vez fomenta el consumo y ayuda a prevenir la pobreza extrema.\\n\\nLo que se dice de la Seguridad Social varía según el contexto y la experiencia de cada país. En general, se reconoce su importancia como pilar fundamental del estado de bienestar, aunque también se discuten desafíos como la sostenibilidad financiera frente al envejecimiento de la población, la informalidad laboral y los cambios en el mercado de trabajo. En algunos países, la eficiencia y calidad de los servicios de Seguridad Social son temas de debate, así como la necesidad de reformas para adaptarse a las nuevas realidades sociales y económicas.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response:  \n",
      "Ratings: [5, 5, 4, None, 5]\n",
      "Processing sample 2: [{\"content\": \"Привет напиши стехотворение в стиле набокова про сложность бытия\", \"role\": \"user\"}, {\"content\": \"Здравствуйте! Я с удовольствием попробую написать стихотворение в стиле Набокова на тему сложности бытия. Владимир Набоков был известен своим изысканным стилем, игрой слов и глубокими размышлениями о природе реальности и человеческого опыта. Вот моя попытка создать стихотворение в его стиле:\\n\\nВ лабиринте дней, где тени ткут узор,\\nГде явь и сон сплетаются в экстаз,\\nБлуждает мысль, как пойманный линкор,\\nВ морях сознанья, что не знают нас.\\n\\nРеальность — лишь иллюзия зеркал,\\nГде каждый миг — загадка и обман.\\nБытия узор так сложен и так мал,\\nЧто растворяется в словесный океан.\\n\\nМы — шахматные фигуры на доске,\\nГде время — гроссмейстер, вечность — мат.\\nИ в каждом ходе, в каждом волоске\\nТаится смысл, непостижимый клад.\\n\\nТак существуем мы — на грани снов,\\nГде прошлое и будущее — дым.\\nИ лишь в игре метафор и основ\\nМы суть свою на миг уловим, мним.\\n\\nЭто стихотворение пытается отразить некоторые ключевые темы и стилистические особенности, характерные для поэзии Набокова:\\n\\n1. Игра с реальностью и иллюзией\\n2. Сложность и многослойность бытия\\n3. Метафоры, связанные с игрой (особенно шахматами)\\n4. Размышления о времени и вечности\\n5. Богатый, образный язык\\n6. Философские размышления, облеченные в поэтическую форму\\n\\nНадеюсь, это стихотворение хотя бы отчасти передает дух набоковской поэзии и размышлений о сложности бытия. Конечно, полностью воссоздать уникальный стиль Набокова — задача чрезвычайно сложная, но я постарался уловить некоторые характерные черты его творчества.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response:  \n",
      "Ratings: [5, 4, 4, None, 4]\n",
      "Processing sample 3: [{\"content\": \"Перефразируй:\\nУкладка бетонной смеси в перекрытие выполняется автобетононасосом в комплекте с автобетоносмесителями и ведется по захваткам в определенном порядке. Захватки определяются из условия сменной (суточной) эксплуатационной производительности автобетононасоса, минимальной дальности подачи бетонной смеси и от того, ведется ли бетонирование только с помощью стрелы автобетононасоса или с помощью бетоновода.\", \"role\": \"user\"}, {\"content\": \"Размещение бетонной массы в конструкции перекрытия осуществляется с использованием автобетононасоса, который работает в сочетании с автобетономешалками. Процесс проходит этапами в строго определенной последовательности. Выбор этапов основывается на дневной производственной мощности автобетононасоса, минимально возможном расстоянии для транспортировки бетонной смеси и зависит от того, производится ли заливка бетона исключительно через стрелу автобетононасоса или с использованием бетонопровода.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response:  \n",
      "Invalid rating value in response: ::::\n",
      "Ratings: [4, 4, 4, None, None]\n",
      "Processing sample 4: [{\"content\": \"Назови три источника и три составные части марксизма\", \"role\": \"user\"}, {\"content\": \"Марксизм является обширной теоретической системой, основанной на работах Карла Маркса и Фридриха Энгельса. Он включает в себя анализ и критику капиталистического общества, теорию исторического развития обществ, а также предложения по организации будущего социалистического общества. Марксизм опирается на множество источников и включает в себя несколько ключевых составляющих.\\n\\nИсточники марксизма:\\n\\n1. **Немецкая классическая философия**. Особенно важным является влияние Гегеля, философии которого Маркс подверг критике и переработке, превратив диалектику из идеалистической в материалистическую. Маркс переосмыслил гегелевскую диалектику, сосредоточив внимание на материальных, а не идеальных основаниях развития общества.\\n\\n2. **Классическая политическая экономия**. Маркс активно изучал и критиковал работы таких экономистов, как Адам Смит и Давид Рикардо. Он использовал их исследования для разработки собственной теории стоимости, прибавочной стоимости и капитала.\\n\\n3. **Французский социализм и утопический социализм**. Идеи социалистов и коммунистов, таких как Шарль Фурье, Генри Сен-Симон и Луи Блан, оказали влияние на Маркса и Энгельса, хотя они и критиковали утопический характер их предложений, стремясь разработать научно обоснованный подход к социализму.\\n\\nСоставные части марксизма:\\n\\n1. **Материалистическое понимание истории** (исторический материализм). Это концепция, согласно которой материальные условия жизни общества определяют его социальные, политические и интеллектуальные процессы. История развития общества представляется как история классовой борьбы.\\n\\n2. **Теория прибавочной стоимости**. Маркс разработал теорию, согласно которой источником прибыли в капиталистическом обществе является эксплуатация рабочего класса, который производит больше стоимости, чем получает в виде заработной платы.\\n\\n3. **Теория классовой борьбы**. Маркс утверждал, что все исторические и существующие общества разделены на классы, между которыми существует антагонистическое противостояние. Основной движущей силой исторического развития является борьба между эксплуатирующими и эксплуатируемыми классами.\\n\\nЭти составляющие и источники формируют основу марксистской теории, которая оказала значительное влияние на развитие социальных наук, политической мысли и истории XX века.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response:  \n",
      "Ratings: [5, 5, 4, None, 4]\n",
      "Skipping sample 5: Size exceeds limit (3728 tokens)\n",
      "Skipping sample 6: Size exceeds limit (10593 tokens)\n",
      "Processing sample 7: [{\"content\": \"Подскажи, пожалуйста, как сделать цикл в ардуино, который бы принимал данные через serial и сохранял их в массив.\", \"role\": \"user\"}, {\"content\": \"Да, конечно, подробно расскажу по шагам.\\n\\nВо-первых, необходимо создать массив, где будут храниться наши данные. Это можно сделать так:\\n\\n```cpp\\nint dataArray[10]; //Массив из 10 элементов\\n```\\n\\nВ данном примере мы создали массив `dataArray`, который может хранить 10 значений int. Но его размер может быть любым, подходящим для ваших нужд.\\n\\nВо-вторых, необходимо считывать данные из serial. Это можно сделать в функции `loop()`. \\n\\n```cpp\\nvoid loop() {\\n  if (Serial.available() > 0) { //Если есть доступные данные\\n    String data = Serial.readStringUntil('\\\\n'); //Считываем данные до конца строки\\n  }\\n}\\n```\\n\\nВ данном примере ардуино будет ожидать доступных данных и, как только они появятся, считывать их до конца строки.\\n\\nВ-третьих, необходимо преобразовать эти данные в int (если это необходимо) и сохранить в массив. \\n\\n```cpp\\nvoid loop() {\\n  if (Serial.available() > 0) { //Если есть доступные данные\\n    String data = Serial.readStringUntil('\\\\n'); //Считываем данные до конца строки\\n    int value = data.toInt(); //Преобразуем данные в int\\n    dataArray[i] = value; //Сохраняем данные в массив\\n    i++; //Переходим к следующему элементу массива\\n  }\\n}\\n```\\n\\nЗдесь мы пока не учли ситуацию переполнения массива. Счётчик `i` может увеличиваться бесконечно, выходя за пределы массива. Следующим шагом будет обнуление счетчика при достижении предела массива.\\n\\n```cpp\\nint i = 0; //Счётчик для массива\\n\\nvoid loop() {\\n  if (Serial.available() > 0) { //Если есть доступные данные\\n    String data = Serial.readStringUntil('\\\\n'); //Считываем данные до конца строки\\n    int value = data.toInt(); //Преобразуем данные в int\\n    dataArray[i] = value; //Сохраняем данные в массив\\n    i++; //Переходим к следующему элементу массива\\n    if (i >= 10) { //Если достигнут конец массива\\n      i = 0; //Обнуляем счётчик\\n    }\\n  }\\n}\\n```\\n\\nТеперь ардуино будет считывать данные из serial, сохранять их в массив и обнулять счётчик по достижении конца массива. Надеюсь, это помогло!\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response:  \n",
      "Invalid rating value in response: :::::\n",
      "Ratings: [5, 5, 4, None, None]\n",
      "Processing sample 8: [{\"content\": \"\\nIdentifica la función de un texto cuyo propósito es manifestar emociones, sentimientos y opiniones\\na. Apelativa\\nb. Referencial\\nc. Fática\\nd. Expresiva\", \"role\": \"user\"}, {\"content\": \"d. Expresiva\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response:  \n",
      "Invalid rating value in response: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ratings: [5, 5, 4, None, None]\n",
      "Skipping sample 9: Size exceeds limit (7171 tokens)\n",
      "Processing sample 10: [{\"content\": \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\", \"role\": \"system\"}, {\"content\": \"Оьъясни для чего нужна температура в llm\", \"role\": \"user\"}, {\"content\": \"Температура (temperature) в контексте языковых моделей (LLM, Large Language Models) — это параметр, который управляет степенью случайности при генерации текста. Она определяет, насколько модель будет \\\"рисковать\\\" при выборе следующего слова в предложении.\\n\\n- **Низкая температура (например, 0.2):** Модель будет более консервативной и выбирать слова с высокой вероятностью. Это приводит к более предсказуемым и менее разнообразным ответам.\\n- **Высокая температура (например, 1.0 и выше):** Модель будет более склонна выбирать менее вероятные слова, что может сделать текст более креативным и разнообразным, но также может увеличить риск генерации менее связного или логичного текста.\\n\\nТемпература позволяет пользователям настраивать поведение модели в зависимости от задачи: для более точных и предсказуемых ответов можно использовать низкую температуру, а для более творческих и разнообразных — высокую.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response:  \n",
      "Ratings: [5, 5, 4, None, 4]\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T22:39:55.964484Z",
     "start_time": "2024-08-14T22:39:55.929874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process each element concurrently using a pool of experts and take a quorum vote\n",
    "quorum = len(experts) // 2 + 1  # Calculate the minimum number of experts to get a majority vote\n",
    "\n",
    "# Calculate the average rating and classify it as \"bad\" or \"good\" for each sample\n",
    "for i, data in enumerate(data_to_rate):\n",
    "    \n",
    "    # Count the number of tokens in the sample using Tiktoken\n",
    "    num_tokens = len(encoding.encode(data))\n",
    "    # Skip processing for large samples with more than 3000 tokens\n",
    "    if num_tokens > 3000:\n",
    "        print(\"Sample {}: Skipping due to size exceeds limit ({} tokens)\".format(i + 1, num_tokens))\n",
    "        continue\n",
    "    \n",
    "    # average_rating = statistics.mean(ratings_by_experts[expert.model] for expert in experts\n",
    "    average_rating = sum(\n",
    "        ratings_by_experts[i][expert.model]\n",
    "        for expert in experts if ratings_by_experts[i][expert.model] is not None\n",
    "    ) / len([expert for expert in experts if ratings_by_experts[i][expert.model] is not None])\n",
    "    print(\"Sample {}: Average rating is {:.2f}\".format(i + 1, average_rating))\n",
    "\n",
    "    # Determine if the majority vote has been achieved\n",
    "    majority_vote = sum(1 for expert in experts if ratings_by_experts[i][expert.model] == int(average_rating)) >= quorum\n",
    "\n",
    "\n",
    "    if not majority_vote:\n",
    "        print(\"Warning: Majority vote not achieved.\")\n",
    "\n",
    "    # Classify the average rating as \"bad\" or \"good\" based on a threshold of 3.5\n",
    "    if average_rating < 3.5:\n",
    "        print(\"Classification: Bad\")\n",
    "    else:\n",
    "        print(\"Classification: Good\")"
   ],
   "id": "d0798be8b3dade52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Average rating is 4.75\n",
      "Warning: Majority vote not achieved.\n",
      "Classification: Good\n",
      "Sample 2: Average rating is 4.25\n",
      "Classification: Good\n",
      "Sample 3: Average rating is 4.00\n",
      "Classification: Good\n",
      "Sample 4: Average rating is 4.50\n",
      "Warning: Majority vote not achieved.\n",
      "Classification: Good\n",
      "Sample 5: Skipping due to size exceeds limit (3728 tokens)\n",
      "Sample 6: Skipping due to size exceeds limit (10593 tokens)\n",
      "Sample 7: Average rating is 4.67\n",
      "Warning: Majority vote not achieved.\n",
      "Classification: Good\n",
      "Sample 8: Average rating is 4.67\n",
      "Warning: Majority vote not achieved.\n",
      "Classification: Good\n",
      "Sample 9: Skipping due to size exceeds limit (7171 tokens)\n",
      "Sample 10: Average rating is 4.50\n",
      "Warning: Majority vote not achieved.\n",
      "Classification: Good\n"
     ]
    }
   ],
   "execution_count": 68
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
