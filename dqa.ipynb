{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T10:41:11.231640Z",
     "start_time": "2024-08-15T10:41:11.202226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def load_config(filename: str) -> object:\n",
    "    file = open(filename).read()\n",
    "    return yaml.safe_load(file)"
   ],
   "id": "255aea07e253c63e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T10:41:11.237785Z",
     "start_time": "2024-08-15T10:41:11.233512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_template(filename: str) -> str:\n",
    "    file = open(filename, 'r').read()\n",
    "    return file"
   ],
   "id": "35a01221e6c6b6f7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T10:41:11.939540Z",
     "start_time": "2024-08-15T10:41:11.245994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jinja2 import Template\n",
    "from openai import OpenAI\n",
    "from settings import OPENAI_API_KEY, OPENAI_BASE_URL, MAX_TOKENS_OUTPUT, PROMPT_TEMPLATE\n",
    "\n",
    "\n",
    "class Expert:\n",
    "    client = None\n",
    "\n",
    "    def __init__(self, model, base_url=None, api_key=None, prompt_template=None):\n",
    "        self.model = model\n",
    "        self.base_url = base_url or OPENAI_BASE_URL\n",
    "        self.api_key = api_key or OPENAI_API_KEY\n",
    "        self.prompt_template = prompt_template or PROMPT_TEMPLATE\n",
    "\n",
    "        if self.client is None:\n",
    "            self.init_client()\n",
    "\n",
    "    def init_client(self):\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def rate_sample(self, sample: str) -> int | None:\n",
    "        prompt = Template(self.prompt_template).render(context=sample)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages,\n",
    "            temperature=0, n=1, max_tokens=MAX_TOKENS_OUTPUT\n",
    "        )\n",
    "\n",
    "        # Extract the response text and parse it as an integer rating from 1 to 5\n",
    "        response_text = response.choices[0].message.content\n",
    "        try:\n",
    "            rating = int(''.join(filter(str.isdigit, response_text)))\n",
    "        except ValueError:\n",
    "            print(\"Invalid rating value in response: {}\".format(response_text))\n",
    "            return None\n",
    "\n",
    "        # Ensure the rating is within the valid range [1, 5]\n",
    "        if rating < 1: rating = 1\n",
    "        if rating > 5: rating = 5\n",
    "\n",
    "        return rating"
   ],
   "id": "4ef84fcab26ca504",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T10:41:17.899120Z",
     "start_time": "2024-08-15T10:41:11.941446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import concurrent.futures\n",
    "from datasets import load_dataset\n",
    "import tiktoken\n",
    "\n",
    "config = load_config('experts.yml')\n",
    "template = load_template('prompt_template.txt')\n",
    "experts = [Expert(**expert, prompt_template=template) for expert in config['experts']]\n",
    "encoding = tiktoken.get_encoding(\"gpt2\")  # Load the Tiktoken encoding model for counting tokens\n",
    "\n",
    "\n",
    "# Processing function, due to limitation of concurrent requests in python\n",
    "def process_model(expert: Expert, data: str) -> int:\n",
    "    return expert.rate_sample(data)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"IlyaGusev/saiga_scored\", split=\"train[:10]\")  # Replace with your desired dataset name\n",
    "\n",
    "# Get the data to rate from the dataset\n",
    "data_to_rate = [json.dumps(sample[\"messages\"], ensure_ascii=False) for sample in dataset]"
   ],
   "id": "9420ea9de5dd79c9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T10:41:48.952991Z",
     "start_time": "2024-08-15T10:41:17.900324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import concurrent.futures\n",
    "from settings import MAX_TOKENS_INPUT\n",
    "\n",
    "\n",
    "def rate_sample(sample: str, experts: list, max_workers: int = 4):\n",
    "    # Count the number of tokens in the sample\n",
    "    num_tokens = len(encoding.encode(sample))\n",
    "    if num_tokens > MAX_TOKENS_INPUT:\n",
    "        print(f\"Skipping sample: Size exceeds limit ({num_tokens} tokens)\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Processing sample: {sample}\")\n",
    "\n",
    "    # Define a function to be executed by each worker\n",
    "    def rate_expert(expert):\n",
    "        return expert.model, process_model(expert, sample)\n",
    "\n",
    "    # Create a thread pool with the specified number of workers\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        ratings = list(executor.map(rate_expert, experts))\n",
    "\n",
    "    # Convert the list of tuples into a dictionary\n",
    "    ratings_by_expert = {model: rating for model, rating in ratings}\n",
    "    print(\"Ratings:\", ratings_by_expert)\n",
    "\n",
    "    return ratings_by_expert\n",
    "\n",
    "\n",
    "# max_workers = 1\n",
    "max_workers = len(experts)\n",
    "\n",
    "# Example usage\n",
    "ratings_by_experts = []\n",
    "for i, data in enumerate(data_to_rate):\n",
    "    ratings_by_expert = rate_sample(data, experts, max_workers=max_workers)\n",
    "    ratings_by_experts.append(ratings_by_expert)"
   ],
   "id": "733eb4a40b245364",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample: [{\"content\": \"Ideas generales de la Seguridad Social (qué es, para qué sirve, qué has oído\\ndecir de ella...)\", \"role\": \"user\"}, {\"content\": \"La Seguridad Social es un sistema integral diseñado para proteger a los ciudadanos frente a diversas situaciones de vulnerabilidad o necesidad, tales como la vejez, el desempleo, la enfermedad, la discapacidad, la muerte (protección a los dependientes del fallecido) y la maternidad. Este sistema se basa en principios de solidaridad y redistribución de recursos, donde los trabajadores, empleadores y, en algunos casos, el Estado, contribuyen financieramente para sostenerlo.\\n\\nLa Seguridad Social tiene varios propósitos fundamentales:\\n\\n1. **Protección contra la pérdida de ingresos**: Asegura un ingreso básico a las personas que no pueden trabajar debido a vejez, enfermedad, discapacidad, maternidad o desempleo.\\n\\n2. **Acceso a servicios de salud**: Ofrece cobertura de salud para el tratamiento de enfermedades y condiciones médicas, así como para la prevención de estas.\\n\\n3. **Apoyo a familias y dependientes**: Proporciona beneficios a las familias con hijos y en algunos casos, apoyo financiero en caso de muerte de un miembro de la familia que contribuía económicamente.\\n\\n4. **Promoción de la equidad social**: A través de la redistribución de recursos, busca reducir las desigualdades económicas y promover la inclusión social.\\n\\n5. **Estabilidad económica**: Contribuye a la estabilidad económica general al asegurar un nivel mínimo de ingresos para todos, lo que a su vez fomenta el consumo y ayuda a prevenir la pobreza extrema.\\n\\nLo que se dice de la Seguridad Social varía según el contexto y la experiencia de cada país. En general, se reconoce su importancia como pilar fundamental del estado de bienestar, aunque también se discuten desafíos como la sostenibilidad financiera frente al envejecimiento de la población, la informalidad laboral y los cambios en el mercado de trabajo. En algunos países, la eficiencia y calidad de los servicios de Seguridad Social son temas de debate, así como la necesidad de reformas para adaptarse a las nuevas realidades sociales y económicas.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response: ::::::::\n",
      "Ratings: {'gpt-3.5-turbo': 4, 'anthropic/claude-3-haiku': 5, 'perplexity/llama-3-sonar-small-32k-online': 4, 'google/palm-2-chat-bison-32k': 4, 'google/gemma-2-9b-it': None}\n",
      "Processing sample: [{\"content\": \"Привет напиши стехотворение в стиле набокова про сложность бытия\", \"role\": \"user\"}, {\"content\": \"Здравствуйте! Я с удовольствием попробую написать стихотворение в стиле Набокова на тему сложности бытия. Владимир Набоков был известен своим изысканным стилем, игрой слов и глубокими размышлениями о природе реальности и человеческого опыта. Вот моя попытка создать стихотворение в его стиле:\\n\\nВ лабиринте дней, где тени ткут узор,\\nГде явь и сон сплетаются в экстаз,\\nБлуждает мысль, как пойманный линкор,\\nВ морях сознанья, что не знают нас.\\n\\nРеальность — лишь иллюзия зеркал,\\nГде каждый миг — загадка и обман.\\nБытия узор так сложен и так мал,\\nЧто растворяется в словесный океан.\\n\\nМы — шахматные фигуры на доске,\\nГде время — гроссмейстер, вечность — мат.\\nИ в каждом ходе, в каждом волоске\\nТаится смысл, непостижимый клад.\\n\\nТак существуем мы — на грани снов,\\nГде прошлое и будущее — дым.\\nИ лишь в игре метафор и основ\\nМы суть свою на миг уловим, мним.\\n\\nЭто стихотворение пытается отразить некоторые ключевые темы и стилистические особенности, характерные для поэзии Набокова:\\n\\n1. Игра с реальностью и иллюзией\\n2. Сложность и многослойность бытия\\n3. Метафоры, связанные с игрой (особенно шахматами)\\n4. Размышления о времени и вечности\\n5. Богатый, образный язык\\n6. Философские размышления, облеченные в поэтическую форму\\n\\nНадеюсь, это стихотворение хотя бы отчасти передает дух набоковской поэзии и размышлений о сложности бытия. Конечно, полностью воссоздать уникальный стиль Набокова — задача чрезвычайно сложная, но я постарался уловить некоторые характерные черты его творчества.\", \"role\": \"bot\"}]\n",
      "Ratings: {'gpt-3.5-turbo': 5, 'anthropic/claude-3-haiku': 4, 'perplexity/llama-3-sonar-small-32k-online': 5, 'google/palm-2-chat-bison-32k': 4, 'google/gemma-2-9b-it': 4}\n",
      "Processing sample: [{\"content\": \"Перефразируй:\\nУкладка бетонной смеси в перекрытие выполняется автобетононасосом в комплекте с автобетоносмесителями и ведется по захваткам в определенном порядке. Захватки определяются из условия сменной (суточной) эксплуатационной производительности автобетононасоса, минимальной дальности подачи бетонной смеси и от того, ведется ли бетонирование только с помощью стрелы автобетононасоса или с помощью бетоновода.\", \"role\": \"user\"}, {\"content\": \"Размещение бетонной массы в конструкции перекрытия осуществляется с использованием автобетононасоса, который работает в сочетании с автобетономешалками. Процесс проходит этапами в строго определенной последовательности. Выбор этапов основывается на дневной производственной мощности автобетононасоса, минимально возможном расстоянии для транспортировки бетонной смеси и зависит от того, производится ли заливка бетона исключительно через стрелу автобетононасоса или с использованием бетонопровода.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response: :::::::\n",
      "Ratings: {'gpt-3.5-turbo': 5, 'anthropic/claude-3-haiku': 4, 'perplexity/llama-3-sonar-small-32k-online': 4, 'google/palm-2-chat-bison-32k': 4, 'google/gemma-2-9b-it': None}\n",
      "Processing sample: [{\"content\": \"Назови три источника и три составные части марксизма\", \"role\": \"user\"}, {\"content\": \"Марксизм является обширной теоретической системой, основанной на работах Карла Маркса и Фридриха Энгельса. Он включает в себя анализ и критику капиталистического общества, теорию исторического развития обществ, а также предложения по организации будущего социалистического общества. Марксизм опирается на множество источников и включает в себя несколько ключевых составляющих.\\n\\nИсточники марксизма:\\n\\n1. **Немецкая классическая философия**. Особенно важным является влияние Гегеля, философии которого Маркс подверг критике и переработке, превратив диалектику из идеалистической в материалистическую. Маркс переосмыслил гегелевскую диалектику, сосредоточив внимание на материальных, а не идеальных основаниях развития общества.\\n\\n2. **Классическая политическая экономия**. Маркс активно изучал и критиковал работы таких экономистов, как Адам Смит и Давид Рикардо. Он использовал их исследования для разработки собственной теории стоимости, прибавочной стоимости и капитала.\\n\\n3. **Французский социализм и утопический социализм**. Идеи социалистов и коммунистов, таких как Шарль Фурье, Генри Сен-Симон и Луи Блан, оказали влияние на Маркса и Энгельса, хотя они и критиковали утопический характер их предложений, стремясь разработать научно обоснованный подход к социализму.\\n\\nСоставные части марксизма:\\n\\n1. **Материалистическое понимание истории** (исторический материализм). Это концепция, согласно которой материальные условия жизни общества определяют его социальные, политические и интеллектуальные процессы. История развития общества представляется как история классовой борьбы.\\n\\n2. **Теория прибавочной стоимости**. Маркс разработал теорию, согласно которой источником прибыли в капиталистическом обществе является эксплуатация рабочего класса, который производит больше стоимости, чем получает в виде заработной платы.\\n\\n3. **Теория классовой борьбы**. Маркс утверждал, что все исторические и существующие общества разделены на классы, между которыми существует антагонистическое противостояние. Основной движущей силой исторического развития является борьба между эксплуатирующими и эксплуатируемыми классами.\\n\\nЭти составляющие и источники формируют основу марксистской теории, которая оказала значительное влияние на развитие социальных наук, политической мысли и истории XX века.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response: :::::::\n",
      "Ratings: {'gpt-3.5-turbo': 5, 'anthropic/claude-3-haiku': 5, 'perplexity/llama-3-sonar-small-32k-online': 4, 'google/palm-2-chat-bison-32k': 4, 'google/gemma-2-9b-it': None}\n",
      "Processing sample: [{\"content\": \"Напишите развёрнутый доклад о языковых моделях.\", \"role\": \"user\"}, {\"content\": \"Доклад о языковых моделях\\n\\n1. Введение\\nЯзыковые модели являются стежками искусственного интеллекта и машинного обучения и играют ключевую роль во многих приложениях, связанных с обработкой естественного языка (NLP), таких как машинный перевод, обнаружение тональности, определение темы текста, исправление ошибок и даже компьютерные игры.\\n\\nВ этом докладе мы рассмотрим основные понятия и подходы к построению языковых моделей, их развитие, преимущества и недостатки различных техник, а также возможные пути дальнейшего развития этой области.\\n\\n2. Основные понятия\\nЯзыковая модель представляет собой математическую модель, описывающую структуру естественного языка. Основная задача языковых моделей заключается в определении вероятностного распределения последовательности слов или символов, т.е. определении вероятности возникновения данной последовательности слов в тексте на естественном языке.\\n\\n3. Подходы к построению языковых моделей\\nРазработка языковых моделей на протяжении последних десятилетий вызвала множество алгоритмических подходов, которые можно разделить на две основные категории - статистические модели и нейронные модели.\\n\\n3.1. Статистические модели\\nСтатистические модели состоят из n-граммных и марковских моделей. В n-граммных моделях каждое n-ое слово последовательности предсказывается на основе предыдущих (n-1) слов, а вероятность всей последовательности равна произведению вероятностей слов, причем вероятности оцениваются на основе их частоты в языковых реалиях. Недостатками статистических моделей являются слабая способность к обобщению и требование больших объемов данных.\\n\\n3.2. Нейронные модели\\nНейронные модели получили широкое распространение в последние годы и привели к значительному прогрессу в области машинного обучения и NLP. Основную массу нейронных моделей составляют модели на основе рекуррентных нейронных сетей (RNN) и трансформеров.\\n\\n- Рекуррентные нейронные сети (RNN)\\nRNN отличаются способностью сохранять информацию о предыдущих состояниях и используют эту информацию при предсказании будущих состояний. Однако, RNN страдают от проблемы затухания и взрывного градиента, что ограничивает их способность моделировать долгосрочные зависимости.\\n\\n- Трансформеры\\nТрансформеры представляют собой архитектуру, основанную на механизих внимания (attention), которые могут эффективно опознавать и использовать долгосрочные зависимости в данных. Трансформеры получили широкое распространение в последние годы и стали основой разработки таких моделей, как BERT, GPT и T5.\\n\\n4. Текущие достижения и перспективы развития\\nЯзыковые модели сильно продвинулись и стали основой разработки таких решений, как Google Translate, Siri, Alexa и другие. Основные направления развития языковых моделей сегодня выглядят следующим образом:\\n\\n- Улучшение универсальности моделей, чтобы они смогли использоваться во множестве различных задач;\\n- Улучшение интерпретируемости моделей, чтобы пользователи смогли понимать логику работы алгоритма;\\n- Работа над уменьшением размера моделей, а также на ускорении обучения и предсказания;\\n- Разработка моделей низкого ресурса для редких языков.\\n\\n5. Заключение\\nЯзыковые модели активно развиваются и являются ключевым фактором прогресса в области обработки естественного языка. Здесь мы рассмотрели основные подходы, архитектуры и приложения языковых моделей, а также возможные пути дальнейшего развития этой области.\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response: :::::::\n",
      "Ratings: {'gpt-3.5-turbo': 5, 'anthropic/claude-3-haiku': 5, 'perplexity/llama-3-sonar-small-32k-online': 4, 'google/palm-2-chat-bison-32k': 4, 'google/gemma-2-9b-it': None}\n",
      "Skipping sample: Size exceeds limit (10593 tokens)\n",
      "Processing sample: [{\"content\": \"Подскажи, пожалуйста, как сделать цикл в ардуино, который бы принимал данные через serial и сохранял их в массив.\", \"role\": \"user\"}, {\"content\": \"Да, конечно, подробно расскажу по шагам.\\n\\nВо-первых, необходимо создать массив, где будут храниться наши данные. Это можно сделать так:\\n\\n```cpp\\nint dataArray[10]; //Массив из 10 элементов\\n```\\n\\nВ данном примере мы создали массив `dataArray`, который может хранить 10 значений int. Но его размер может быть любым, подходящим для ваших нужд.\\n\\nВо-вторых, необходимо считывать данные из serial. Это можно сделать в функции `loop()`. \\n\\n```cpp\\nvoid loop() {\\n  if (Serial.available() > 0) { //Если есть доступные данные\\n    String data = Serial.readStringUntil('\\\\n'); //Считываем данные до конца строки\\n  }\\n}\\n```\\n\\nВ данном примере ардуино будет ожидать доступных данных и, как только они появятся, считывать их до конца строки.\\n\\nВ-третьих, необходимо преобразовать эти данные в int (если это необходимо) и сохранить в массив. \\n\\n```cpp\\nvoid loop() {\\n  if (Serial.available() > 0) { //Если есть доступные данные\\n    String data = Serial.readStringUntil('\\\\n'); //Считываем данные до конца строки\\n    int value = data.toInt(); //Преобразуем данные в int\\n    dataArray[i] = value; //Сохраняем данные в массив\\n    i++; //Переходим к следующему элементу массива\\n  }\\n}\\n```\\n\\nЗдесь мы пока не учли ситуацию переполнения массива. Счётчик `i` может увеличиваться бесконечно, выходя за пределы массива. Следующим шагом будет обнуление счетчика при достижении предела массива.\\n\\n```cpp\\nint i = 0; //Счётчик для массива\\n\\nvoid loop() {\\n  if (Serial.available() > 0) { //Если есть доступные данные\\n    String data = Serial.readStringUntil('\\\\n'); //Считываем данные до конца строки\\n    int value = data.toInt(); //Преобразуем данные в int\\n    dataArray[i] = value; //Сохраняем данные в массив\\n    i++; //Переходим к следующему элементу массива\\n    if (i >= 10) { //Если достигнут конец массива\\n      i = 0; //Обнуляем счётчик\\n    }\\n  }\\n}\\n```\\n\\nТеперь ардуино будет считывать данные из serial, сохранять их в массив и обнулять счётчик по достижении конца массива. Надеюсь, это помогло!\", \"role\": \"bot\"}]\n",
      "Invalid rating value in response: :::::::\n",
      "Ratings: {'gpt-3.5-turbo': 5, 'anthropic/claude-3-haiku': 5, 'perplexity/llama-3-sonar-small-32k-online': 4, 'google/palm-2-chat-bison-32k': 4, 'google/gemma-2-9b-it': None}\n",
      "Processing sample: [{\"content\": \"\\nIdentifica la función de un texto cuyo propósito es manifestar emociones, sentimientos y opiniones\\na. Apelativa\\nb. Referencial\\nc. Fática\\nd. Expresiva\", \"role\": \"user\"}, {\"content\": \"d. Expresiva\", \"role\": \"bot\"}]\n",
      "Ratings: {'gpt-3.5-turbo': 5, 'anthropic/claude-3-haiku': 5, 'perplexity/llama-3-sonar-small-32k-online': 4, 'google/palm-2-chat-bison-32k': 5, 'google/gemma-2-9b-it': 5}\n",
      "Skipping sample: Size exceeds limit (7171 tokens)\n",
      "Processing sample: [{\"content\": \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\", \"role\": \"system\"}, {\"content\": \"Оьъясни для чего нужна температура в llm\", \"role\": \"user\"}, {\"content\": \"Температура (temperature) в контексте языковых моделей (LLM, Large Language Models) — это параметр, который управляет степенью случайности при генерации текста. Она определяет, насколько модель будет \\\"рисковать\\\" при выборе следующего слова в предложении.\\n\\n- **Низкая температура (например, 0.2):** Модель будет более консервативной и выбирать слова с высокой вероятностью. Это приводит к более предсказуемым и менее разнообразным ответам.\\n- **Высокая температура (например, 1.0 и выше):** Модель будет более склонна выбирать менее вероятные слова, что может сделать текст более креативным и разнообразным, но также может увеличить риск генерации менее связного или логичного текста.\\n\\nТемпература позволяет пользователям настраивать поведение модели в зависимости от задачи: для более точных и предсказуемых ответов можно использовать низкую температуру, а для более творческих и разнообразных — высокую.\", \"role\": \"bot\"}]\n",
      "Ratings: {'gpt-3.5-turbo': 5, 'anthropic/claude-3-haiku': 5, 'perplexity/llama-3-sonar-small-32k-online': 4, 'google/palm-2-chat-bison-32k': 4, 'google/gemma-2-9b-it': 4}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T10:41:48.988790Z",
     "start_time": "2024-08-15T10:41:48.959285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import statistics\n",
    "\n",
    "\n",
    "def classify_rating(ratings_by_experts: list, quorum: int):\n",
    "    classified_samples = []\n",
    "\n",
    "    for i, ratings in enumerate(ratings_by_experts):\n",
    "\n",
    "        # Skip empty ratings\n",
    "        if ratings is None:\n",
    "            continue\n",
    "\n",
    "        # Count the number of valid (non-None) ratings\n",
    "        valid_ratings = [rating for rating in ratings.values() if rating is not None]\n",
    "\n",
    "        # Check if the number of valid ratings meets or exceeds the quorum\n",
    "        majority_vote = True\n",
    "        if len(valid_ratings) < quorum:\n",
    "            majority_vote = False\n",
    "            print(f\"Sample {i + 1}: Not enough valid ratings. Skipping classification.\")\n",
    "\n",
    "        # Calculate the average rating\n",
    "        average_rating = statistics.mean(valid_ratings)\n",
    "        classification = \"Good\" if average_rating > 3.5 else \"Bad\"\n",
    "\n",
    "        # Check for a majority vote\n",
    "        print(f\"Sample {i + 1}: AVG Rating: {average_rating}, Class: {classification}\")\n",
    "        print(f\"Ratings: {json.dumps(valid_ratings)}\")\n",
    "        print(f\"Majority Vote Achieved: {majority_vote}\")\n",
    "        print(f\"\")\n",
    "\n",
    "        classified_samples.append({\n",
    "            \"sample_index\": i + 1,\n",
    "            \"average_rating\": average_rating,\n",
    "            \"classification\": classification,\n",
    "            \"majority_vote\": majority_vote\n",
    "        })\n",
    "\n",
    "    return classified_samples if classified_samples else None\n",
    "\n",
    "\n",
    "# Process each element concurrently using a pool of experts and take a quorum vote\n",
    "quorum = (len(experts) // 2) + 1  # (50%+1) calculate the minimum number of experts to get a majority vote\n",
    "\n",
    "# Calculate the average rating and classify it as \"bad\" or \"good\" for each sample\n",
    "results = classify_rating(ratings_by_experts, quorum)\n",
    "results"
   ],
   "id": "d0798be8b3dade52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: AVG Rating: 4.25, Class: Good\n",
      "Ratings: [4, 5, 4, 4]\n",
      "Majority Vote Achieved: True\n",
      "\n",
      "Sample 2: AVG Rating: 4.4, Class: Good\n",
      "Ratings: [5, 4, 5, 4, 4]\n",
      "Majority Vote Achieved: True\n",
      "\n",
      "Sample 3: AVG Rating: 4.25, Class: Good\n",
      "Ratings: [5, 4, 4, 4]\n",
      "Majority Vote Achieved: True\n",
      "\n",
      "Sample 4: AVG Rating: 4.5, Class: Good\n",
      "Ratings: [5, 5, 4, 4]\n",
      "Majority Vote Achieved: True\n",
      "\n",
      "Sample 5: AVG Rating: 4.5, Class: Good\n",
      "Ratings: [5, 5, 4, 4]\n",
      "Majority Vote Achieved: True\n",
      "\n",
      "Sample 7: AVG Rating: 4.5, Class: Good\n",
      "Ratings: [5, 5, 4, 4]\n",
      "Majority Vote Achieved: True\n",
      "\n",
      "Sample 8: AVG Rating: 4.8, Class: Good\n",
      "Ratings: [5, 5, 4, 5, 5]\n",
      "Majority Vote Achieved: True\n",
      "\n",
      "Sample 10: AVG Rating: 4.4, Class: Good\n",
      "Ratings: [5, 5, 4, 4, 4]\n",
      "Majority Vote Achieved: True\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sample_index': 1,\n",
       "  'average_rating': 4.25,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True},\n",
       " {'sample_index': 2,\n",
       "  'average_rating': 4.4,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True},\n",
       " {'sample_index': 3,\n",
       "  'average_rating': 4.25,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True},\n",
       " {'sample_index': 4,\n",
       "  'average_rating': 4.5,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True},\n",
       " {'sample_index': 5,\n",
       "  'average_rating': 4.5,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True},\n",
       " {'sample_index': 7,\n",
       "  'average_rating': 4.5,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True},\n",
       " {'sample_index': 8,\n",
       "  'average_rating': 4.8,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True},\n",
       " {'sample_index': 10,\n",
       "  'average_rating': 4.4,\n",
       "  'classification': 'Good',\n",
       "  'majority_vote': True}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
